{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photonic Classifier Smoke Tests\n",
    "\n",
    "This notebook contains a series of \"smoke tests\" for the `p_pack` module. The purpose is to provide a quick way to run basic checks on individual functions during development.\n",
    "\n",
    "**How to use this notebook:**\n",
    "1.  Use `Ctrl+F` or `Cmd+F` to find the function you are working on.\n",
    "2.  Run the test cell for that function to see if it passes.\n",
    "3.  The cell immediately below the test will display the source code of the function being tested, allowing you to compare the test with the implementation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import unittest\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import itertools\n",
    "from jax.scipy.special import factorial\n",
    "from p_pack import globals, circ, loss, model, optimiser, pre_p, train\n",
    "\n",
    "# Import all the modules from the package\n",
    "# Assuming 'p_pack' is a valid package in your environment\n",
    "# from p_pack import circ, globals, loss, model, optimiser, pre_p, train\n",
    "\n",
    "# Helper function to display the source code of a function\n",
    "def show_code(func):\n",
    "    \"\"\"\n",
    "    Displays the source code of a given function.\n",
    "    Handles regular and JIT-compiled functions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        source_lines, _ = inspect.getsourcelines(func)\n",
    "        print(\"Source Code:\")\n",
    "        # Corrected line: Use an empty string \"\" to join the source lines.\n",
    "        print(\"\".join(source_lines))\n",
    "    except TypeError as e:\n",
    "        print(f\"Could not get source for {func}: {e}\")\n",
    "        print(\"This can happen with JIT-compiled functions. Showing the .py_func attribute if available.\")\n",
    "        if hasattr(func, 'py_func'):\n",
    "            source_lines, _ = inspect.getsourcelines(func.py_func)\n",
    "            print(\"Source Code (from .py_func):\")\n",
    "            # Corrected line: Same fix as above.\n",
    "            print(\"\".join(source_lines))\n",
    "\n",
    "# This function will run a single test case\n",
    "def run_test(test_class, test_name):\n",
    "    \"\"\"\n",
    "    Creates a test suite for a single test case and runs it.\n",
    "    \"\"\"\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(test_class(test_name))\n",
    "    runner = unittest.TextTestRunner()\n",
    "    print(f\"--- Running test: {test_name} ---\")\n",
    "    result = runner.run(suite)\n",
    "    if not result.wasSuccessful():\n",
    "        print(f\"--- Test Failed: {test_name} ---\")\n",
    "    else:\n",
    "        print(f\"--- Test Passed: {test_name} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OG init checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output state combinations: [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 2]\n",
      " [0 0 3]\n",
      " [0 0 4]\n",
      " [0 0 5]\n",
      " [0 0 6]\n",
      " [0 0 7]\n",
      " [0 0 8]\n",
      " [0 0 9]\n",
      " [0 1 1]\n",
      " [0 1 2]\n",
      " [0 1 3]\n",
      " [0 1 4]\n",
      " [0 1 5]\n",
      " [0 1 6]\n",
      " [0 1 7]\n",
      " [0 1 8]\n",
      " [0 1 9]\n",
      " [0 2 2]]\n",
      "Random matrix: [[-0.28371066  0.9368162  -1.0050073 ]\n",
      " [ 1.4165013   1.0543301   0.9108127 ]\n",
      " [-0.42656708  0.986188   -0.5575324 ]\n",
      " [ 0.01532502 -2.078568    0.5548371 ]\n",
      " [ 0.91423655  0.5744596   0.7227863 ]\n",
      " [ 0.12106175 -0.3237354   1.6234998 ]\n",
      " [ 0.24500391 -1.3809781  -0.6111237 ]\n",
      " [ 0.1403725   0.84100425 -1.0943578 ]\n",
      " [-1.077502   -1.1396457  -0.593338  ]\n",
      " [-0.15576515 -0.38321444 -1.1144515 ]]\n",
      "Extracted submatrices: [[[-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.28371066  0.9368162  -1.0050073 ]]\n",
      "\n",
      " [[-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [ 1.4165013   1.0543301   0.9108127 ]]\n",
      "\n",
      " [[-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.42656708  0.986188   -0.5575324 ]]\n",
      "\n",
      " [[-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [ 0.01532502 -2.078568    0.5548371 ]]\n",
      "\n",
      " [[-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [-0.28371066  0.9368162  -1.0050073 ]\n",
      "  [ 0.91423655  0.5744596   0.7227863 ]]]\n",
      "[3 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 2]\n",
      "Factorials of repeats: [6.0000052 2.0000005 2.0000005 2.0000005 2.0000005 2.0000005 2.0000005\n",
      " 2.0000005 2.0000005 2.0000005 2.0000005 1.0000005 1.0000005 1.0000005\n",
      " 1.0000005 1.0000005 1.0000005 1.0000005 1.0000005 2.0000005]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "out_state_combos = jnp.array(list(itertools.combinations_with_replacement(range(10), 3)))\n",
    "print('Output state combinations:', out_state_combos[:20])\n",
    "\n",
    "def extract_submatrices(unitary):\n",
    "    # unitary: (num_modes, 3)\n",
    "    # out_state_combos: (n_combos, 3)\n",
    "    return unitary[out_state_combos[:5], :] \n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "random_matrix = jax.random.normal(key, (10, 3))\n",
    "print('Random matrix:', random_matrix)\n",
    "\n",
    "extracted_submatrices = extract_submatrices(random_matrix)\n",
    "print('Extracted submatrices:', extracted_submatrices[:10])\n",
    "\n",
    "# Count repeats for each combo\n",
    "def count_repeats(combo):\n",
    "    # Count occurrences of each value\n",
    "    unique, counts = jnp.unique(combo, return_counts=True)\n",
    "    # Only count repeats (counts > 1)\n",
    "    repeats = counts[counts > 1]\n",
    "    return repeats.sum() #- repeats.size  # subtract 1 for each unique repeated value\n",
    "\n",
    "# Vectorize over all combos\n",
    "repeats_per_combo = jnp.array([count_repeats(combo) for combo in out_state_combos])\n",
    "\n",
    "print(repeats_per_combo[:20])\n",
    "\n",
    "factorials = factorial(repeats_per_combo)\n",
    "\n",
    "print('Factorials of repeats:', factorials[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Not needed for now:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m( \u001b[43mtrain_set\u001b[49m.shape, train_labels.shape, test_set.shape, test_labels.shape)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Initialize the phases\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# each feature has its own uploading BS so we had a factor of 2\u001b[39;00m\n\u001b[32m      8\u001b[39m init_phases = circ.initialize_phases(\u001b[32m10\u001b[39m, \u001b[32m2\u001b[39m*num_features, )  \n",
      "\u001b[31mNameError\u001b[39m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "# Not needed for now:\n",
    "\n",
    "print( train_set.shape, train_labels.shape, test_set.shape, test_labels.shape)\n",
    "\n",
    "# Initialize the phases\n",
    "\n",
    "# each feature has its own uploading BS so we had a factor of 2\n",
    "init_phases = circ.initialize_phases(10, 2*num_features, )  \n",
    "\n",
    "weights_data = jnp.ones(shape = [init_phases.shape[0],init_phases.shape[1]]) #weights for data reuploading\n",
    "#print(init_phases)\n",
    "#print(init_phases)\n",
    "\n",
    "# If you didn't test any of the jitted functions yet, the ratio in times should be around a factor 10^3 - 10^5.\n",
    "# The first time is larger because of the compilation.\n",
    "# The second time is small because it just runs the compiled code.\n",
    "# Also, try to get any of these run times in pure Python+Numpy.\n",
    "b = time.time()\n",
    "# The block_until_ready is supposed to only let Python continue when the compiled code has finished.\n",
    "# For me, it's not reliable. Therefore, I print the results first before measuring the end time.\n",
    "result1, result2, result3, x = jax.block_until_ready(model.full_unitaries_data_reupload)(init_phases, train_set, weights_data)\n",
    "print(result1.shape)\n",
    "print(result2.shape)\n",
    "print(result3.shape)\n",
    "e = time.time()\n",
    "print(e-b)\n",
    "b = time.time()\n",
    "result1 , result2, result3, x  = jax.block_until_ready(model.full_unitaries_data_reupload)(init_phases, train_set, weights_data)\n",
    "print(result1.shape)\n",
    "print(result2.shape)\n",
    "print(result3.shape)\n",
    "\n",
    "e = time.time()\n",
    "print(e-b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check multiphoton output combinations\n",
    "\n",
    "# Example usage of the measurement function\n",
    "n = 3  # number of matrices\n",
    "size = 6  # size of each identity matrix\n",
    "\n",
    "# Create a (n, 1, 1) array of factors: [0], [1], [2]\n",
    "factors = jnp.arange(n, dtype=jnp.complex64).reshape(-1, 1, 1)\n",
    "# Create a (1, 6, 6) identity matrix and broadcast\n",
    "ones_matrix = jnp.arange(n * size * size, dtype=jnp.complex64).reshape(n, size, size)\n",
    "# Multiply to get (n, 6, 6)\n",
    "temp_unitaries = factors * ones_matrix\n",
    "\n",
    "#print(temp_unitaries.shape)  # (3, 6, 6)\n",
    "#print(temp_unitaries)\n",
    "\n",
    "result_measurement, combos1, probs1, _ = measurement(temp_unitaries, num_photons = 3)\n",
    "#print(probs1)\n",
    "#print(result_measurement.shape)  # Should be (num_samples, 2, 6) if num_samples is the batch size\n",
    "parity = jnp.sum(combos1, axis=1) % 2\n",
    "mask = (parity == 1)  # shape (n_combos,)\n",
    "\n",
    "arr = jnp.arange(1, 21)\n",
    "test = parity*arr\n",
    "test1 = mask*arr\n",
    "print(\"Masked array:\", test1)\n",
    "print(\"Even indices:\", test)\n",
    "print(parity)  # 0 = even, 1 = odd\n",
    "print(combos1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check permanent calculation\n",
    "\n",
    "def perm_3x3_jax(mat):\n",
    "    # Only works for 3x3 matrices\n",
    "    perms = jnp.array([\n",
    "        [0, 1, 2],\n",
    "        [0, 2, 1],\n",
    "        [1, 0, 2],\n",
    "        [1, 2, 0],\n",
    "        [2, 0, 1],\n",
    "        [2, 1, 0]\n",
    "    ])\n",
    "    return jnp.sum(jnp.prod(mat[jnp.arange(3), perms], axis=1))\n",
    "\n",
    "# Example usage\n",
    "mat = jnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=jnp.complex64)\n",
    "result_perm = perm_3x3_jax(mat) \n",
    "print(\"Permanent of the matrix:\", result_perm)  # Should print the permanent of the matrix\n",
    "mat1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=jnp.complex64)\n",
    "print(\"Permanent of the matrix (using numpy):\", perm(mat1))  # For comparison with numpy's perm function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `initialize_phases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.058s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shape ---\n",
      "--- Test Passed: test_shape ---\n"
     ]
    }
   ],
   "source": [
    "class TestInitializePhases(unittest.TestCase):\n",
    "    def test_shape(self):\n",
    "        \"\"\"Test the phase initialization function.\"\"\"\n",
    "        depth, width = 5, 8\n",
    "        phases = circ.initialize_phases(depth, width)\n",
    "        self.assertEqual(phases.shape, (depth, width // 2, 2))\n",
    "\n",
    "run_test(TestInitializePhases, 'test_shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Code:\n",
      "def initialize_phases(depth: int, width: int = None, mask: np.ndarray = None) -> jnp.array:\n",
      "    \"\"\"\n",
      "    Initializes the phase parameters for the photonic circuit.Ã¥\n",
      "\n",
      "    The phases are initialized with small random values to avoid barren plateaus.\n",
      "    A mask can be provided to fix certain phases to zero, making them non-trainable.\n",
      "    By default, data-uploading layers (determined by `reupload_freq`) are masked out.\n",
      "\n",
      "    Args:\n",
      "        depth (int): The number of layers in the circuit.\n",
      "        width (Optional[int]): The number of modes in the circuit. Defaults to `depth`.\n",
      "        mask (Optional[np.ndarray]): A binary mask to apply to the phases.\n",
      "                                     A value of 0 freezes a phase.\n",
      "\n",
      "    Returns:\n",
      "        jnp.array: A JAX array of initialized phases.\n",
      "    \"\"\"\n",
      "    # Default case is Clements et al. layout, with all beam splitters tunable.\n",
      "    if width == None:\n",
      "        width = depth \n",
      "    if mask == None:\n",
      "        mask = np.ones(shape = [depth, width//2, 2])\n",
      "        #mask = np.zeros((depth, width // 2, 2))\n",
      "        for i in range(0,depth, reupload_freq):  # every reupload_freq-th layer is a uploading layer \n",
      "            mask[i] = 0\n",
      "\n",
      "    # // 2 is integer division by 2, including rounding down.\n",
      "    # The last two says that these two phases belong  to the same beamsplitter.\n",
      "    # That is also why we divide the width by 2.\n",
      "    phases = rng.uniform( low = -0.1, high = 0.1 , size =  [depth, width//2, 2])\n",
      "    # The mask allows to set some phases to zero. This can be used if one wants to \n",
      "    # fix some beam splitters to the identity, for example for modularity.\n",
      "    phases = mask*phases   \n",
      "    phases = jnp.array(phases)\n",
      "    return phases\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_code(circ.initialize_phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `layer_unitary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_unitarity ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.814s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Passed: test_unitarity ---\n"
     ]
    }
   ],
   "source": [
    "class TestLayerUnitary(unittest.TestCase):\n",
    "    def test_unitarity(self):\n",
    "        \"\"\"Test the layer unitary creation and check for unitarity.\"\"\"\n",
    "        depth, width = 5, 8\n",
    "        all_phases = circ.initialize_phases(depth, width)\n",
    "        layer_idx = 2\n",
    "        \n",
    "        # FIX: The math in the original layer_unitary was incorrect.\n",
    "        # The function has been corrected in the source file to use a standard\n",
    "        # unitary beamsplitter parameterization.\n",
    "        unitary = circ.layer_unitary(all_phases, layer_idx)\n",
    "        self.assertEqual(unitary.shape, (width, width))\n",
    "        \n",
    "        identity = jnp.eye(width, dtype=jnp.complex64)\n",
    "        product = unitary @ unitary.T.conj()\n",
    "        self.assertTrue(jnp.allclose(product, identity, atol=1e-6))\n",
    "\n",
    "run_test(TestLayerUnitary, 'test_unitarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Code:\n",
      "@partial(jax.jit, static_argnames=['layer'])\n",
      "def layer_unitary(all_phases: jnp.array, layer: int, mask: jnp.array = None) -> jnp.array:\n",
      "    \"\"\"\n",
      "    Constructs the unitary matrix for a single trainable layer of the circuit.\n",
      "\n",
      "    Args:\n",
      "        all_phases (jnp.array): The full tensor of phase parameters for all layers.\n",
      "        layer (int): The index of the layer to construct the unitary for.\n",
      "        mask (Optional[jnp.array]): An optional mask to apply to the layer's phases.\n",
      "\n",
      "    Returns:\n",
      "        jnp.array: The complex-valued unitary matrix for the specified layer.\n",
      "    \"\"\"\n",
      "    #layer = jax.lax.stop_gradient(layer) # doesn't work, don't ask me why.\n",
      "    \n",
      "    width = 2*jax.lax.stop_gradient(all_phases).shape[1] \n",
      "    # Stopping the gradient here allows to use the size of an input tensor to define other tensors.\n",
      "    # Depth of the trainable part.\n",
      "    depth = jax.lax.stop_gradient(all_phases).shape[0]\n",
      "    if mask == None:\n",
      "        # The default mask allows all phases to be trained\n",
      "        mask = jnp.ones(shape = [depth, width//2])\n",
      "    trainable_layer_phases = jnp.zeros(shape = [width//2 , 2])\n",
      "    # Notice that the scalar operation '*' is applied for each beamsplitter of the layer individually, \n",
      "    # hidden in the fact that mask[layer] still has a dimension for the width, and the ':'.\n",
      "\n",
      "    # below retrieves a given layer's phases from the all_phases tensor\n",
      "    trainable_layer_phases = trainable_layer_phases.at[:, 0].set(mask[layer]*all_phases[layer,:,0])\n",
      "    trainable_layer_phases = trainable_layer_phases.at[:, 1].set(mask[layer]*all_phases[layer,:,1])\n",
      "    \n",
      "    unitary = jnp.zeros(shape = [width, width], dtype = jnp.complex64)\n",
      "    # Odd layers get an offset of one for placing beamsplitters.\n",
      "    \n",
      "    offset = (layer) % 2\n",
      "    # Take care of wires that do not see a beamsplitter in this layer.\n",
      "    if offset == 1:\n",
      "        unitary = unitary.at[0,0].set(1.0)\n",
      "        # If the width is even and the offset is one, also the last wire does not get a beamsplitter.\n",
      "        if width % 2 == 0:\n",
      "            # -1 gives the last entry\n",
      "            unitary = unitary.at[-1, -1].set(1.0)\n",
      "    else:  # Offset is 0, so for odd number of wires the last one cannot get a beamsplitter.  \n",
      "        if width % 2 == 1:\n",
      "            unitary = unitary.at[-1,-1].set(1.0)  \n",
      "            \n",
      "    # Now, write the actual layers\n",
      "    # Since the entries look so different, I have no clever idea for how to vectorize/broadcast this...\n",
      "    for index in range( (width-offset)//2):\n",
      "        p = trainable_layer_phases[index,0]\n",
      "        q = trainable_layer_phases[index,1]\n",
      "        # Taken from old code. However, for p=q=0, it does not give the identity. Therefore the mask doesn't work.\n",
      "        #unitary = unitary.at[offset+2*index, offset+2*index].set(jnp.exp(p*1j)*jnp.sin(q/2))\n",
      "        #unitary = unitary.at[offset+2*index , offset+2*index+1].set(jnp.cos(q/2))\n",
      "        #unitary =  unitary.at[offset+2*index+1, offset+2*index].set(jnp.exp(p*1j)*jnp.cos(q/2))\n",
      "        #unitary = unitary.at[offset+2*index+1, offset+2*index+1].set(-jnp.sin(q/2))\n",
      "        \n",
      "        # To get the mask to work, I am using a different parameterization.\n",
      "        unitary = unitary.at[offset + 2*index,  offset + 2*index].set(0.5*(1 + jnp.exp(1j*p)))\n",
      "        unitary = unitary.at[offset + 2*index,  offset + 2*index + 1].set(0.5*(jnp.exp(1j*q) - jnp.exp(1j*(q+p))))\n",
      "        unitary = unitary.at[offset + 2*index + 1, offset + 2*index].set(0.5*(1 - jnp.exp(1j*p)))\n",
      "        unitary = unitary.at[offset + 2*index + 1, offset + 2*index + 1].set(0.5*(jnp.exp(1j*q) + jnp.exp(1j*(q+p))))\n",
      "\n",
      "       #need to create a diagram to illustrate how this unitary is made, need to comfirm how this is\n",
      "\n",
      "\n",
      "    # Taken from old code to remind myself.\n",
      "    #splitters = jnp.array([[jnp.exp(p*1j)*np.sin(q/2), np.cos(q/2)], [np.exp(p*1j)*np.cos(q/2), -np.sin(q/2)]] for q,p in [q_all, p_all])\n",
      "\n",
      "    return unitary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_code(circ.layer_unitary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `data_upload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shape ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.356s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Passed: test_shape ---\n"
     ]
    }
   ],
   "source": [
    "class TestDataUpload(unittest.TestCase):\n",
    "    def test_shape(self):\n",
    "        \"\"\"Test the data upload mechanism.\"\"\"\n",
    "        num_samples, feature_dim = 10, 4\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        unitary = circ.data_upload(data_set)\n",
    "        self.assertEqual(unitary.shape, (num_samples, feature_dim * 2, feature_dim * 2))\n",
    "\n",
    "run_test(TestDataUpload, 'test_shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Code:\n",
      "@jax.jit\n",
      "def data_upload(data_set: jnp.array) -> jnp.array:\n",
      "    \"\"\"\n",
      "    Constructs the unitary matrices for the data uploading layer.\n",
      "\n",
      "    This function creates a batch of block-diagonal unitary matrices, where each\n",
      "    matrix encodes one sample (e.g., an image) from the input data set.\n",
      "\n",
      "    Args:\n",
      "        data_set (jnp.array): The input data, with shape (num_samples, num_features).\n",
      "\n",
      "    Returns:\n",
      "        jnp.array: A batch of unitary matrices with shape (num_samples, width, width).\n",
      "    \"\"\"\n",
      "    num_samples = jax.lax.stop_gradient(data_set).shape[0]\n",
      "\n",
      "    # Each pixel gets its BS, therefore factor 2 for counting overall system width\n",
      "    width = 2*jax.lax.stop_gradient(data_set).shape[1]\n",
      "    # Again, the 3rd dimension with 2 represents the two phases for each beamsplitter. \n",
      "\n",
      "    # is this the fastest way to fill the array with what we want or ist here a faster way\n",
      "    phases = (jnp.pi/2)*jnp.ones(shape = [num_samples, width//2, 2]) \n",
      "    # The first of the phases of the beam splitters are set to be the feature values, the second phases are set \n",
      "    # to a constant pi/2 . 0 doesn't work because minimal and maximal pixel brightness act on the uniform superposition\n",
      "    # state identically, with the parameterization below. For q = pi/2, minimal and maximal pixel brightness move the\n",
      "    # uniform superposition into orthogonal states.  \n",
      "    phases = phases.at[:,:,0].set(data_set)\n",
      "\n",
      "    # Note that our \"unitary\" has 3 dimensions. The 1st dimension is a batching dimension, \n",
      "    # representing the index of the image. This allows to parallelize the calculation of hthe loss \n",
      "    # over the full training set later.\n",
      "    \n",
      "    unitary = jnp.zeros(shape = [num_samples, width, width], dtype = jnp.complex64)    \n",
      "    for index in range( width//2 ):    \n",
      "        #print('yes')\n",
      "        p = phases[:, index, 0]\n",
      "        q = phases[:, index, 1]\n",
      "        # Note that p and q are 1-dimensional tensors here. We use that all operations here like jnp.exp are \n",
      "        # applied entry-by-entry to calculate the uploading unitary for all images in parallel.\n",
      "        # That means each entry of p and q corresponds to one image, which corresponds to \n",
      "        # one entry in the : in dimension 0. \n",
      "        unitary = unitary.at[:,2*index, 2*index].set(0.5*(1+jnp.exp(1j*p)))\n",
      "        unitary = unitary.at[:,2*index , 2*index+1].set(0.5*(jnp.exp(1j*q)-jnp.exp(1j*(q+p))))\n",
      "        unitary = unitary.at[:,2*index+1, 2*index].set(0.5*(1-jnp.exp(1j*p)))\n",
      "        unitary = unitary.at[:,2*index+1, 2*index+1].set(0.5*(jnp.exp(1j*q)+jnp.exp(1j*(q+p))))\n",
      "\n",
      "    return unitary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_code(circ.data_upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `measurement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shapes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.340s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Passed: test_shapes ---\n"
     ]
    }
   ],
   "source": [
    "class TestMeasurement(unittest.TestCase):\n",
    "    def test_shapes(self):\n",
    "        \"\"\"Test the measurement function.\"\"\"\n",
    "        num_samples, num_modes = 10, globals.num_modes_circ\n",
    "        dummy_unitaries = jnp.array([jnp.eye(num_modes, dtype=jnp.complex64)] * num_samples)\n",
    "        \n",
    "        sub_unitaries, combos, probs, binary_probs = circ.measurement(dummy_unitaries)\n",
    "\n",
    "        self.assertIsNotNone(sub_unitaries)\n",
    "        self.assertIsNotNone(combos)\n",
    "        self.assertEqual(probs.shape[0], num_samples)\n",
    "        self.assertEqual(binary_probs.shape, (num_samples, 1))\n",
    "\n",
    "run_test(TestMeasurement, 'test_shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Code:\n",
      "def measurement(unitaries: jnp.array, num_photons: int = 3) -> tuple[jnp.array, jnp.array, jnp.array, jnp.array]:\n",
      "    \"\"\"\n",
      "    Simulates the measurement process of the photonic circuit.\n",
      "\n",
      "    It calculates the probabilities of detecting photons in different output modes,\n",
      "    computes the permanents of submatrices, and aggregates these into binary\n",
      "    classification probabilities (+1 or -1) based on the parity of output modes.\n",
      "\n",
      "    Args:\n",
      "        unitaries (jnp.array): The batch of final unitary matrices from the circuit.\n",
      "        num_photons (int): The number of photons in the input state. Defaults to 3.\n",
      "        factorials (jnp.array): Pre-computed factorial values for probability calculation.\n",
      "\n",
      "    Returns:\n",
      "        Tuple[jnp.array, jnp.array, jnp.array, jnp.array]: A tuple containing:\n",
      "            - all_extracts: The submatrices used for permanent calculation.\n",
      "            - out_state_combos: All possible output state combinations.\n",
      "            - all_probs: The raw probability for each output combination.\n",
      "            - binary_probs: The final aggregated probability for the +1 outcome.\n",
      "    \"\"\"\n",
      "    n = unitaries.shape[0]\n",
      "    num_modes = unitaries.shape[1]\n",
      "    #out_state_combos = jnp.array(list(combinations(range(num_modes), num_photons)))\n",
      "    \n",
      "    out_state_combos = jnp.array(list(itertools.combinations_with_replacement(range(num_modes), num_photons)))\n",
      "    n_combos = out_state_combos.shape[0]\n",
      "\n",
      "    factorials_dyn = repeats_factorials(num_modes=unitaries.shape[-1],\n",
      "                                    num_photons=num_photons)\n",
      "\n",
      "    parity_out_state_combos = jnp.sum(out_state_combos, axis=1) % 2\n",
      "\n",
      "    # Truncate to first 3 columns\n",
      "    #print('Unitaries', unitaries[:5, :, :])\n",
      "    input_state_modes = jnp.array([0, num_modes//2, num_modes-1])\n",
      "    # photons are always in the first, middle and last modes\n",
      "    unitaries_truncated = unitaries[:, :, input_state_modes]\n",
      "\n",
      "    \n",
      "    # Vectorized extraction of submatrices for all samples and all combos\n",
      "    def extract_submatrices(unitary):\n",
      "        # unitary: (num_modes, 3)\n",
      "        # out_state_combos: (n_combos, 3)\n",
      "        return unitary[out_state_combos, :]  # (n_combos, 3, 3)\n",
      "\n",
      "    # Apply to all samples--\n",
      "    all_extracts = jax.vmap(extract_submatrices)(unitaries_truncated)  # (n, n_combos, 3, 3)\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "    # Vectorized permanent calculation over all submatrices\n",
      "    perm_fn = jax.vmap(lambda mat: jnp.abs(perm_3x3_jax(mat))**2)\n",
      "    all_probs0 = jax.vmap(perm_fn, in_axes=0)(all_extracts)  # (n, n_combos)\n",
      "    #print('Truncated unitaries', unitaries_truncated[0, :, :])\n",
      "    #print('All probs0', all_probs0[:,:10])\n",
      "    #print(\"Combo :\", out_state_combos[:10])\n",
      "    #print(\"Sample submatrix for combo 216:\", all_extracts[0, :5])\n",
      "    #print(\"Permanent for sample:\", perm_3x3_jax(all_extracts[0, :5]))\n",
      "    all_probs = all_probs0 / factorials_dyn  # Broadcasting over columns\n",
      "    #print('All probs', all_probs.shape)\n",
      "    # Now, for each row in all_probs, every column is divided by the corresponding factorial.\n",
      "    ##\n",
      "    plus_1_probs = all_probs * parity_out_state_combos\n",
      "    plus_minus1_probs = all_probs * (1 - parity_out_state_combos)\n",
      "    #print('Plus 1 probs', plus_1_probs[:10, :5])\n",
      "    # Sum over all output state probabilities for each sample\n",
      "    total_probs = jnp.sum(all_probs, axis=1, keepdims=True)  # shape (n, 1)\n",
      "    #print('Total probs', total_probs)\n",
      "    #need to verify if total_probs is correct\n",
      "\n",
      "    # Normalise all probabilities\n",
      "    all_probs_norm = all_probs / total_probs\n",
      "    plus_1_probs_norm = plus_1_probs / total_probs\n",
      "    plus_minus1_probs_norm = plus_minus1_probs / total_probs\n",
      "\n",
      "    # Normalised binary probabilities\n",
      "    binary_probs = jnp.sum(plus_1_probs_norm, axis=1, keepdims=True)\n",
      "    binary_probs_minus = jnp.sum(plus_minus1_probs_norm, axis=1, keepdims=True)\n",
      "\n",
      "    # Optionally print to check\n",
      "    #print('Sum of all_probs_norm (should be 1):', jnp.sum(all_probs_norm, axis=1))\n",
      "    #print('Sum of binary_probs + binary_probs_minus (should be 1):', (binary_probs + binary_probs_minus).squeeze())\n",
      "    \n",
      "    ##\n",
      "\n",
      "    \n",
      "    # 0 = even (-1), 1 = odd (+1)\n",
      "    #even_indices = jnp.where(parity_out_state_combos == 0)[0]\n",
      "    \n",
      "    #plus_1_probs = all_probs*parity_out_state_combos\n",
      "    #plus_minus1_probs = all_probs*(1-parity_out_state_combos)\n",
      "    #print(plus_1_probs[:10, :5])\n",
      "    #binary_probs = jnp.sum(plus_1_probs, axis=1, keepdims=True)\n",
      "    #binary_probs_minus = jnp.sum(plus_minus1_probs, axis=1, keepdims=True)\n",
      "\n",
      "\n",
      "    #total_probs = binary_probs + binary_probs_minus\n",
      "    #print('total_probs', total_probs[:10])\n",
      "    #print('minus', binary_probs_minus[:10])  \n",
      "    #print('plus',binary_probs[:10])\n",
      "    #print('plus total sum', jnp.sum(binary_probs))\n",
      "    #print('minus total sum', jnp.sum(binary_probs_minus))\n",
      "  \n",
      "    return all_extracts, out_state_combos, all_probs, binary_probs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_code(circ.measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.pre_p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `rescale_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.035s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_scaling ---\n",
      "--- Test Passed: test_scaling ---\n"
     ]
    }
   ],
   "source": [
    "class TestRescaleData(unittest.TestCase):\n",
    "    def test_scaling(self):\n",
    "        \"\"\"Test the data rescaling function.\"\"\"\n",
    "        data = jnp.array([-10., 0., 10.])\n",
    "        min_val, max_val = -np.pi / 2, np.pi / 2\n",
    "        rescaled = pre_p.rescale_data(data, min_val, max_val)\n",
    "        \n",
    "        self.assertTrue(jnp.all(rescaled >= min_val))\n",
    "        self.assertTrue(jnp.all(rescaled <= max_val))\n",
    "\n",
    "run_test(TestRescaleData, 'test_scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(pre_p.rescale_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `load_mnist_35`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_loading (__main__.TestLoadMnist.test_loading)\n",
      "Test loading data from a CSV file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/7v/6bnphj4937q9tbp6zlbd71pr0000gn/T/ipykernel_8293/1892411339.py\", line 20, in test_loading\n",
      "    self.assertEqual(X.shape, (5, self.feature_dim))\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: Tuples differ: (4, 4) != (5, 4)\n",
      "\n",
      "First differing element 0:\n",
      "4\n",
      "5\n",
      "\n",
      "- (4, 4)\n",
      "?  ^\n",
      "\n",
      "+ (5, 4)\n",
      "?  ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.114s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_loading ---\n",
      "--- Test Failed: test_loading ---\n"
     ]
    }
   ],
   "source": [
    "class TestLoadMnist(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Create a dummy CSV file for testing.\"\"\"\n",
    "        self.test_dir = \"test_data_temp\"\n",
    "        os.makedirs(self.test_dir, exist_ok=True)\n",
    "        self.feature_dim = 4\n",
    "        self.fname = f\"mnist_3-5_{self.feature_dim}d_train.csv\"\n",
    "        self.path = os.path.join(self.test_dir, self.fname)\n",
    "        data = np.random.rand(5, self.feature_dim + 1)\n",
    "        pd.DataFrame(data).to_csv(self.path, index=False, header=False)\n",
    "\n",
    "    def tearDown(self):\n",
    "        \"\"\"Remove the dummy CSV and directory.\"\"\"\n",
    "        os.remove(self.path)\n",
    "        os.rmdir(self.test_dir)\n",
    "\n",
    "    def test_loading(self):\n",
    "        \"\"\"Test loading data from a CSV file.\"\"\"\n",
    "        X, y = pre_p.load_mnist_35(self.test_dir, self.feature_dim, split=\"train\")\n",
    "        self.assertEqual(X.shape, (5, self.feature_dim))\n",
    "        self.assertEqual(y.shape, (5,))\n",
    "\n",
    "run_test(TestLoadMnist, 'test_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(pre_p.load_mnist_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `full_unitaries_data_reupload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shapes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_shapes (__main__.TestFullUnitaries.test_shapes)\n",
      "Test the function that builds the full unitary for the model.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 174, in _broadcast_shapes_uncached\n",
      "    return _try_broadcast_shapes(*rank_promoted_shapes, name='broadcast_shapes')\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 128, in _try_broadcast_shapes\n",
      "    raise TypeError(f'{name} got incompatible shapes for broadcasting: '\n",
      "                    f'{\", \".join(map(str, map(tuple, shapes)))}.')\n",
      "TypeError: broadcast_shapes got incompatible shapes for broadcasting: (10, 512), (1, 216).\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 152, in broadcast_shapes\n",
      "    return _broadcast_shapes_cached(*shapes)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/util.py\", line 302, in wrapper\n",
      "    return cached(config.trace_context() if trace_context_in_key else _ignore(),\n",
      "                  *args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/util.py\", line 296, in cached\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 158, in _broadcast_shapes_cached\n",
      "    return _broadcast_shapes_uncached(*shapes)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 177, in _broadcast_shapes_uncached\n",
      "    raise ValueError(f\"Incompatible shapes for broadcasting: shapes={list(shapes)}\") from err\n",
      "ValueError: Incompatible shapes for broadcasting: shapes=[(10, 512), (216,)]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 174, in _broadcast_shapes_uncached\n",
      "    return _try_broadcast_shapes(*rank_promoted_shapes, name='broadcast_shapes')\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 128, in _try_broadcast_shapes\n",
      "    raise TypeError(f'{name} got incompatible shapes for broadcasting: '\n",
      "                    f'{\", \".join(map(str, map(tuple, shapes)))}.')\n",
      "TypeError: broadcast_shapes got incompatible shapes for broadcasting: (10, 512), (1, 216).\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/7v/6bnphj4937q9tbp6zlbd71pr0000gn/T/ipykernel_8293/2581610446.py\", line 11, in test_shapes\n",
      "    outputs = model.full_unitaries_data_reupload(phases, data_set, weights)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/p_pack/model.py\", line 65, in full_unitaries_data_reupload\n",
      "    sub_unitaries, _, label_probs, binary_probs_plus = circ.measurement(unitaries, num_photons = 3)\n",
      "                                                       ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/p_pack/circ.py\", line 339, in measurement\n",
      "    all_probs = all_probs0 / factorials  # Broadcasting over columns\n",
      "                ~~~~~~~~~~~^~~~~~~~~~~~\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/array_methods.py\", line 573, in deferring_binary_op\n",
      "    return binary_op(*args)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/traceback_util.py\", line 180, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 337, in cache_miss\n",
      "    pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)\n",
      "                     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 177, in _python_pjit_helper\n",
      "    p, args_flat = _infer_params(fun, jit_info, args, kwargs)\n",
      "                   ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 769, in _infer_params\n",
      "    p, args_flat = _infer_params_impl(\n",
      "                   ~~~~~~~~~~~~~~~~~~^\n",
      "        fun, ji, pjit_mesh, resource_env, args, kwargs, in_avals=avals)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 651, in _infer_params_impl\n",
      "    jaxpr, consts, out_avals, attrs_tracked = _create_pjit_jaxpr(\n",
      "                                              ~~~~~~~~~~~~~~~~~~^\n",
      "        flat_fun, in_type, attr_token, dbg,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        HashableFunction(res_paths, closure=()),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        IgnoreKey(ji.inline))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 335, in memoized_fun\n",
      "    ans = call(fun, *args)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 1315, in _create_pjit_jaxpr\n",
      "    jaxpr, global_out_avals, consts, attrs_tracked = pe.trace_to_jaxpr_dynamic(\n",
      "                                                     ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        fun, in_type, debug_info=pe_debug)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/profiler.py\", line 333, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/interpreters/partial_eval.py\", line 2189, in trace_to_jaxpr_dynamic\n",
      "    ans = fun.call_wrapped(*in_tracers)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 187, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 294, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 74, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 691, in result_paths\n",
      "    ans = _fun(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/ufuncs.py\", line 2445, in true_divide\n",
      "    x1, x2 = promote_args_inexact(\"true_divide\", x1, x2)\n",
      "             ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/util.py\", line 211, in promote_args_inexact\n",
      "    return promote_shapes(fun_name, *promote_dtypes_inexact(*args))\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/util.py\", line 59, in promote_shapes\n",
      "    result_rank = len(lax.broadcast_shapes(*shapes))\n",
      "                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 154, in broadcast_shapes\n",
      "    return _broadcast_shapes_uncached(*shapes)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 177, in _broadcast_shapes_uncached\n",
      "    raise ValueError(f\"Incompatible shapes for broadcasting: shapes={list(shapes)}\") from err\n",
      "ValueError: Incompatible shapes for broadcasting: shapes=[(10, 512), (216,)]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.765s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Failed: test_shapes ---\n"
     ]
    }
   ],
   "source": [
    "class TestFullUnitaries(unittest.TestCase):\n",
    "    def test_shapes(self):\n",
    "        \"\"\"Test the function that builds the full unitary for the model.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "\n",
    "        # FIX: The original model.py was missing imports and had NameErrors.\n",
    "        # The source file has been corrected to properly import from circ.\n",
    "        outputs = model.full_unitaries_data_reupload(phases, data_set, weights)\n",
    "        \n",
    "        self.assertEqual(len(outputs), 4)\n",
    "        unitaries, sub_unitaries, label_probs, binary_probs_plus = outputs\n",
    "        self.assertEqual(unitaries.shape[0], num_samples)\n",
    "        self.assertIsNotNone(sub_unitaries)\n",
    "        self.assertEqual(label_probs.shape[0], num_samples)\n",
    "        self.assertEqual(binary_probs_plus.shape, (num_samples, 1))\n",
    "\n",
    "run_test(TestFullUnitaries, 'test_shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(model.full_unitaries_data_reupload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `predict_reupload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPredictReupload(unittest.TestCase):\n",
    "    def test_shapes(self):\n",
    "        \"\"\"Test the prediction function.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "\n",
    "        probs, adjusted_binary_probs = model.predict_reupload(phases, data_set, weights)\n",
    "\n",
    "        self.assertEqual(probs.shape[0], num_samples)\n",
    "        self.assertEqual(adjusted_binary_probs.shape, (num_samples, 1))\n",
    "\n",
    "run_test(TestPredictReupload, 'test_shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(model.predict_reupload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.loss`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoss(unittest.TestCase):\n",
    "    def test_calculation(self):\n",
    "        \"\"\"Test the loss function returns a scalar value.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        labels = jnp.ones(num_samples)\n",
    "\n",
    "        # FIX: The original loss.py had a NameError.\n",
    "        # The source file is corrected to call model.predict_reupload.\n",
    "        loss_value = loss.loss(phases, data_set, labels, weights)\n",
    "        self.assertTrue(jnp.isscalar(loss_value))\n",
    "\n",
    "run_test(TestLoss, 'test_calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(loss.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.optimiser`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `adam_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAdamStep(unittest.TestCase):\n",
    "    def test_step(self):\n",
    "        \"\"\"Test a single step of the Adam optimizer.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        params_phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        params_weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        labels = jnp.ones(num_samples)\n",
    "        m_phases = jnp.zeros_like(params_phases)\n",
    "        v_phases = jnp.zeros_like(params_phases)\n",
    "        m_weights = jnp.zeros_like(params_weights)\n",
    "        v_weights = jnp.zeros_like(params_weights)\n",
    "\n",
    "        carry = [params_phases, data_set, labels, params_weights, m_phases, v_phases, m_weights, v_weights]\n",
    "        step_number = 1\n",
    "\n",
    "        # FIX: The original optimiser.py had a TypeError, calling the loss module.\n",
    "        # The source file is corrected to call loss.loss().\n",
    "        new_carry, loss_info = optimiser.adam_step(carry, step_number)\n",
    "\n",
    "        self.assertEqual(len(new_carry), 8)\n",
    "        self.assertEqual(loss_info.shape, (2,))\n",
    "\n",
    "run_test(TestAdamStep, 'test_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(optimiser.adam_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTrain(unittest.TestCase):\n",
    "    def test_train_run(self):\n",
    "        \"\"\"Test the main training function.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim*2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        labels = jnp.ones(num_samples)\n",
    "        m_phases = jnp.zeros_like(phases)\n",
    "        v_phases = jnp.zeros_like(phases)\n",
    "        m_weights = jnp.zeros_like(weights)\n",
    "        v_weights = jnp.zeros_like(weights)\n",
    "\n",
    "        init = (phases, data_set, labels, weights, m_phases, v_phases, m_weights, v_weights)\n",
    "\n",
    "        # FIX: The original train.py had a NameError.\n",
    "        # The source file is corrected to call optimiser.adam_step.\n",
    "        final_carry, loss_history = train.train(init)\n",
    "\n",
    "        self.assertEqual(len(final_carry), 8)\n",
    "        self.assertEqual(loss_history.shape, (globals.num_steps, 2))\n",
    "\n",
    "run_test(TestTrain, 'test_train_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(train.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
